1. Spark Contexts

        - First and most important step, helps in accessing spark cluster with the help of resource manager
        - SparkConf - used to create context, passes configurations to context which is used by the driver program to define properties, resource allocation (memory, cores,etc.)
        - Flow: Application -> Driver (Context) -> cluster Manager -> Worker node
        - Functions: set configurations, current status of the application, setting up RDDs

3. iCode session

        - Electrode setup
        - Cross site scripting
        - Content security policy (theory and lab)

4. CIP 
        - Lessons
        - Activities
        - Assessments